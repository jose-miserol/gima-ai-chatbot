# Voice Fill - Roadmap de Implementaci√≥n

**Responsables:** Jose Miserol, Omar Castellano
**Feature:** Voice Fill (Relleno por Voz)  
**Prop√≥sito:** Permite dictar notas o actualizaciones sobre la marcha; la IA transcribe el habla directamente en las √≥rdenes de trabajo y solicitudes

---

## Tabla de Contenidos

1. [Visi√≥n General](#visi√≥n-general)
2. [Estructura de Carpetas](#estructura-de-carpetas)
3. [Arquitectura del Sistema](#arquitectura-del-sistema)
4. [Flujo de Trabajo](#flujo-de-trabajo)
5. [Componentes Principales](#componentes-principales)
6. [Server Actions](#server-actions)
7. [Hooks de React](#hooks-de-react)
8. [Servicios](#servicios)
9. [Configuraci√≥n](#configuraci√≥n)
10. [Ejemplos de Uso](#ejemplos-de-uso)

---

## Prerequisitos

Antes de estudiar este roadmap, un desarrollador junior debe entender:

### Conceptos de JavaScript/TypeScript

**Promises y async/await**

```typescript
// Necesitas entender este patr√≥n
const result = await someAsyncFunction();
```

- [MDN: Promises](https://developer.mozilla.org/es/docs/Web/JavaScript/Reference/Global_Objects/Promise)
- [MDN: async/await](https://developer.mozilla.org/es/docs/Web/JavaScript/Reference/Statements/async_function)

**FileReader y Blob**

```typescript
// Conversi√≥n de archivos binarios a texto base64
const reader = new FileReader();
reader.readAsDataURL(blob); // Blob ‚Üí base64 string
```

- [MDN: FileReader](https://developer.mozilla.org/es/docs/Web/API/FileReader)
- [MDN: Blob](https://developer.mozilla.org/es/docs/Web/API/Blob)

### Conceptos de React

**Hooks (useState, useEffect, useCallback)**

```typescript
const [state, setState] = useState(initialValue);
useEffect(() => {
  /* side effect */
}, [dependencies]);
const memoizedCallback = useCallback(() => {
  /* function */
}, [deps]);
```

- [React Docs: Hooks](https://react.dev/reference/react)

**Custom Hooks**

```typescript
// Reutilizaci√≥n de l√≥gica con estado
function useCustomHook() {
  const [value, setValue] = useState();
  return { value, setValue };
}
```

### Conceptos de Next.js

**Server Actions ('use server')**

```typescript
'use server';
export async function myServerAction(data: string) {
  // Se ejecuta en el servidor, no en el navegador
}
```

- [Next.js Docs: Server Actions](https://nextjs.org/docs/app/building-your-application/data-fetching/server-actions-and-mutations)

**Diferencia Client vs Server Components**

- Client: Usa 'use client', puede usar hooks, estado, eventos del navegador
- Server: Ejecuta en servidor, no puede usar hooks, accede a DB directamente

### Web APIs del Navegador

**MediaRecorder API**

```typescript
// Captura audio/video del micr√≥fono
const recorder = new MediaRecorder(stream);
recorder.start(); // Inicia grabaci√≥n
recorder.stop(); // Detiene y dispara evento 'dataavailable'
```

- [MDN: MediaRecorder](https://developer.mozilla.org/es/docs/Web/API/MediaRecorder)

**getUserMedia() para permisos**

```typescript
// Solicita acceso al micr√≥fono
const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
```

### Formatos de Datos

**Base64 Encoding**

- ¬øQu√© es? Representaci√≥n de datos binarios como texto ASCII
- ¬øPor qu√©? Permite enviar audio en JSON (APIs REST requieren texto)
- Formato: `data:audio/webm;base64,UklGRiQAAABXQVZFZm10...`

**MIME Types**

- `audio/webm` - Formato de Chrome/Firefox
- `audio/mp4` - Formato de Safari
- Importante: Cada navegador soporta diferentes codecs

---

## Visi√≥n General

Voice Fill es una funcionalidad que permite a los usuarios **dictar por voz** en lugar de escribir texto manualmente. El sistema:

1. **Captura audio** del micr√≥fono del usuario
2. **Transcribe** usando IA (Gemini Flash Lite)
3. **Procesa** comandos de voz espec√≠ficos (opcional)
4. **Rellena** autom√°ticamente campos de √≥rdenes de trabajo

### Casos de Uso

- T√©cnicos en campo dictando hallazgos
- Creaci√≥n r√°pida de √≥rdenes de trabajo sin teclado
- Actualizaci√≥n de status de activos por voz
- Comandos de navegaci√≥n manos libres

---

## Estructura de Carpetas

### ¬øD√≥nde est√° cada cosa?

```
app/
‚îú‚îÄ‚îÄ actions/
‚îÇ   ‚îú‚îÄ‚îÄ voice.ts                          # ‚≠ê Server Actions principales
‚îÇ   ‚îî‚îÄ‚îÄ __tests__/
‚îÇ       ‚îî‚îÄ‚îÄ actions-voice.test.ts         # Tests de server actions
‚îÇ
‚îú‚îÄ‚îÄ components/features/voice/            # ‚≠ê Componentes UI de voz
‚îÇ   ‚îú‚îÄ‚îÄ voice-button.tsx                  # Bot√≥n de entrada de voz
‚îÇ   ‚îú‚îÄ‚îÄ voice-command-mode.tsx            # Modo comandos de voz
‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ use-voice-command-flow.ts     # Flujo de comandos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ use-voice-navigation.ts       # Navegaci√≥n por voz
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ use-voice-system.ts           # Sistema de voz
‚îÇ   ‚îî‚îÄ‚îÄ __tests__/                        # Tests de componentes
‚îÇ
‚îú‚îÄ‚îÄ components/features/chat/
‚îÇ   ‚îî‚îÄ‚îÄ types/
‚îÇ       ‚îî‚îÄ‚îÄ voice-props.types.ts          # Tipos para props de voz
‚îÇ
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îú‚îÄ‚îÄ use-voice-input.ts                # ‚≠ê Hook principal de entrada de voz
‚îÇ   ‚îî‚îÄ‚îÄ __tests__/
‚îÇ       ‚îî‚îÄ‚îÄ use-voice-input.test.ts       # Tests del hook
‚îÇ
‚îú‚îÄ‚îÄ lib/services/
‚îÇ   ‚îî‚îÄ‚îÄ voice-command-parser.ts           # ‚≠ê Servicio de parsing de comandos
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ voice-command-prompt.ts           # Prompts para comandos
‚îÇ   ‚îî‚îÄ‚îÄ voice-master-prompt.ts            # Prompt master de voz
‚îÇ
‚îî‚îÄ‚îÄ types/
    ‚îú‚îÄ‚îÄ voice-commands.ts                 # Tipos de comandos de voz
    ‚îî‚îÄ‚îÄ __tests__/
        ‚îî‚îÄ‚îÄ voice-commands.test.ts        # Tests de tipos
```

### Leyenda

- ‚≠ê = Archivos cr√≠ticos para entender Voice Fill
- `__tests__/` = Carpetas de tests unitarios

---

## Arquitectura del Sistema

### Diagrama de Flujo

```mermaid
flowchart TD
    A[Usuario con Micr√≥fono] -->|1. Graba audio| B[VoiceButton Component]
    B -->|2. Captura blob| C[useVoiceInput Hook]
    C -->|3. Convierte a base64| D[transcribeAudio Server Action]
    D -->|4. Env√≠a audio + prompt| E[Gemini 2.5 Flash Lite]
    E -->|5. Retorna texto| F[Post-procesamiento]
    F -->|Elimina timestamps| G{Comando o Texto?}
    G -->|Texto simple| H[Callback onTranscript]
    G -->|Comando| I[executeVoiceCommand]
    I -->|Parsea con IA| J[VoiceCommandParser Service]
    J -->|Valida con Zod| K[Comando Estructurado]
    K --> H
    H -->|Actualiza estado| L[UI Component]

    style E fill:#4285f4,color:#fff
    style D fill:#34a853,color:#fff
    style J fill:#fbbc04,color:#000
    style L fill:#ea4335,color:#fff
```

### Capas del Sistema

```mermaid
graph LR
    A[UI Layer] -->|user events| B[Hooks Layer]
    B -->|audio data| C[Server Actions]
    C -->|API calls| D[AI Models]
    C -->|parse| E[Services]
    E -->|validate| F[Schemas]

    subgraph "Client Side"
    A
    B
    end

    subgraph "Server Side"
    C
    D
    E
    F
    end

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e9
    style D fill:#f3e5f5
    style E fill:#fce4ec
    style F fill:#fff9c4
```

| Capa               | Responsabilidad                 | Ubicaci√≥n                              |
| ------------------ | ------------------------------- | -------------------------------------- |
| **UI**             | Captura de audio, visualizaci√≥n | `components/features/voice/`           |
| **Hooks**          | L√≥gica de estado y efectos      | `hooks/use-voice-input.ts`             |
| **Server Actions** | Comunicaci√≥n con IA             | `actions/voice.ts`                     |
| **Servicios**      | Parsing de comandos             | `lib/services/voice-command-parser.ts` |
| **Configuraci√≥n**  | Prompts y constantes            | `config/voice-*.ts`                    |
| **Tipos**          | Definiciones TypeScript         | `types/voice-commands.ts`              |

---

## Flujo de Trabajo

### Paso a Paso: ¬øC√≥mo funciona?

#### 1. Usuario inicia grabaci√≥n

```typescript
// En VoiceButton.tsx
<Button onClick={handleStartRecording}>
  üé§ Hablar
</Button>
```

**¬øQu√© pasa?**

- Se solicita permiso de micr√≥fono
- Se inicia `MediaRecorder`
- El estado cambia a "recording"

#### 2. Usuario habla y detiene

**¬øQu√© pasa?**

- Se captura el audio en un `Blob`
- Se convierte a base64 usando `FileReader`

```typescript
// En use-voice-input.ts
const reader = new FileReader();
reader.onload = () => {
  const base64Audio = reader.result as string;
  // Enviar a transcripci√≥n
};
reader.readAsDataURL(audioBlob);
```

#### 3. Transcripci√≥n en servidor

```typescript
// En actions/voice.ts (Server Action)
export async function transcribeAudio(audioDataUrl: string) {
  const result = await generateText({
    model: google('gemini-2.5-flash-lite'),
    temperature: 0,
    messages: [
      {
        role: 'user',
        content: [
          { type: 'text', text: VOICE_PROMPT },
          { type: 'file', data: base64Content, mediaType: 'audio/webm' },
        ],
      },
    ],
  });

  return { text: cleanText, success: true };
}
```

**¬øPor qu√©?**

- `temperature: 0` ‚Üí Respuestas determin√≠sticas
- `VOICE_PROMPT` ‚Üí Instrucciones para eliminar muletillas
- Limpieza regex ‚Üí Eliminar timestamps `00:00`

#### 4. Retorno y actualizaci√≥n UI

```typescript
// En use-voice-input.ts
const { text, success } = await transcribeAudio(base64Audio);
if (success) {
  onTranscript?.(text); // Callback al componente padre
}
```

#### 5. (Opcional) Parsing de comandos

```typescript
// Si es un comando de voz
const result = await executeVoiceCommand(transcript);
if (result.success) {
  // result.command contiene: action, parameters, confidence
  handleCommand(result.command);
}
```

---

## Componentes Principales

### 1. `VoiceButton.tsx`

**Ubicaci√≥n:** `app/components/features/voice/voice-button.tsx`

**Prop√≥sito:** Bot√≥n UI para capturar audio

**Props:**

```typescript
interface VoiceButtonProps {
  onTranscript: (text: string) => void; // Callback con texto transcrito
  disabled?: boolean; // Deshabilitar bot√≥n
  className?: string; // Clases CSS
}
```

**Estados:**

- `idle` - Esperando click
- `recording` - Grabando audio
- `processing` - Enviando a IA
- `success` - Transcripci√≥n completada
- `error` - Error en el proceso

**Uso:**

```typescript
<VoiceButton
  onTranscript={(text) => setMessage(text)}
  disabled={isLoading}
/>
```

### 2. `VoiceCommandMode.tsx`

**Ubicaci√≥n:** `app/components/features/voice/voice-command-mode.tsx`

**Prop√≥sito:** Modo especial para comandos de √≥rdenes de trabajo

**Caracter√≠sticas:**

- Preview del comando interpretado
- Bot√≥n de confirmar/rechazar
- Visualizaci√≥n de par√°metros extra√≠dos

---

## Server Actions

### `transcribeAudio()`

**Ubicaci√≥n:** `app/actions/voice.ts`

**Firma:**

```typescript
async function transcribeAudio(
  audioDataUrl: string,
  mimeType: string = 'audio/webm'
): Promise<{
  text: string;
  success: boolean;
  error?: string;
}>;
```

**¬øC√≥mo funciona?**

1. **Validaci√≥n de tama√±o**

   ```typescript
   if (sizeInMB > MAX_AUDIO_SIZE_MB) {
     throw new Error(`Audio demasiado grande`);
   }
   ```

2. **Llamada a Gemini**
   - Modelo: `gemini-2.5-flash-lite`
   - Temperature: `0` (determin√≠stico)
   - Prompt: Instrucciones de limpieza

3. **Post-procesamiento**

   ```typescript
   const cleanText = result.text
     .replace(/\d{1,2}:\d{2}/g, '') // Quitar timestamps
     .replace(/\n+/g, ' ') // Unir l√≠neas
     .replace(/\s+/g, ' ') // Espacios dobles
     .trim();
   ```

4. **Manejo de errores**
   - Logging con `logger.error()`
   - Retorno de mensaje de error user-friendly

### `executeVoiceCommand()`

**Ubicaci√≥n:** `app/actions/voice.ts`

**Firma:**

```typescript
async function executeVoiceCommand(
  transcript: string,
  options?: {
    minConfidence?: number;
    context?: string;
  }
);
```

**¬øPara qu√©?**

- Parsea comandos como "Crear orden urgente para la UMA"
- Extrae: acci√≥n, par√°metros, entidades
- Valida con Zod schemas

**Resultado:**

```typescript
{
  success: true,
  command: {
    action: 'create_work_order',
    parameters: {
      priority: 'urgent',
      assetType: 'UMA',
      // ...
    },
    confidence: 0.95
  }
}
```

---

## Hooks de React

### `useVoiceInput()`

**Ubicaci√≥n:** `app/hooks/use-voice-input.ts`

**Prop√≥sito:** Hook principal para captura y transcripci√≥n de voz

**Uso:**

```typescript
const { isRecording, startRecording, stopRecording, transcript, error } = useVoiceInput({
  onTranscript: (text) => console.log(text),
  onError: (err) => console.error(err),
});
```

**¬øQu√© maneja?**

- Permisos de micr√≥fono
- Estado de grabaci√≥n
- Conversi√≥n blob ‚Üí base64
- Llamada a server action
- Manejo de errores

### `useVoiceSystem()`

**Ubicaci√≥n:** `app/components/features/voice/hooks/use-voice-system.ts`

**Prop√≥sito:** Sistema completo de voz con fallback a Web Speech API

**Caracter√≠sticas:**

- Detecci√≥n autom√°tica de soporte
- Fallback si Gemini falla
- Gesti√≥n de permisos

### `useVoiceCommandFlow()`

**Ubicaci√≥n:** `app/components/features/voice/hooks/use-voice-command-flow.ts`

**Prop√≥sito:** Flujo completo de comandos de voz

**Estados:**

- idle ‚Üí listening ‚Üí processing ‚Üí preview ‚Üí confirmed/rejected

---

## Servicios

### `VoiceCommandParserService`

**Ubicaci√≥n:** `app/lib/services/voice-command-parser.ts`

**Patr√≥n:** Singleton

**Responsabilidad:** Parsear comandos de voz en JSON estructurado

**M√©todos:**

#### `parseCommand()`

```typescript
async parseCommand(
  transcript: string,
  options: {
    minConfidence: number,
    context?: string,
    language: string
  }
): Promise<ParseResult>
```

**¬øC√≥mo funciona?**

1. **Env√≠a transcript a Gemini** con prompt de parsing
2. **Recibe JSON estructurado** con comando
3. **Valida con Zod** contra schemas
4. **Retorna comando tipado** o error

**Ejemplo:**

Input:

```
"Crear orden urgente para mantenimiento de la UMA del sector 3"
```

Output:

```typescript
{
  success: true,
  command: {
    type: 'work_order',
    action: 'create_work_order',
    parameters: {
      priority: 'urgent',
      assetType: 'UMA',
      sector: '3',
      taskType: 'maintenance'
    },
    confidence: 0.92
  }
}
```

---

## Configuraci√≥n

### `VOICE_PROMPT`

**Ubicaci√≥n:** `app/config/voice-master-prompt.ts`

**Contenido:**

```typescript
export const VOICE_PROMPT = `
Transcribe el siguiente audio en espa√±ol.
REGLAS ESTRICTAS:
- NO incluyas timestamps (00:00, 01:23, etc.)
- NO incluyas etiquetas de speaker ([Speaker 1])
- NO incluyas muletillas excesivas (ehh, mmm, etc.)
- Retorna SOLO el texto hablado, limpio y natural
`;
```

**¬øPor qu√©?**

- Gemini a veces incluye timestamps
- Necesitamos texto limpio para comandos
- Mejora UX al eliminar ruido

### `VOICE_COMMAND_PROMPT`

**Ubicaci√≥n:** `app/config/voice-command-prompt.ts`

**Prop√≥sito:** Instrucciones para parsear comandos

**Estructura:**

- Descripci√≥n de entidades (UMA, BCA, TAB, ST)
- Formato de respuesta JSON
- Ejemplos de entrenamiento

---

## Ejemplos de Uso

### Ejemplo 1: Transcripci√≥n Simple

```typescript
import { VoiceButton } from '@/app/components/features/voice';

function MyForm() {
  const [description, setDescription] = useState('');

  return (
    <div>
      <Textarea value={description} onChange={(e) => setDescription(e.target.value)} />

      <VoiceButton
        onTranscript={(text) => setDescription(prev => prev + ' ' + text)}
      />
    </div>
  );
}
```

**Resultado:** Usuario habla ‚Üí Texto se agrega al textarea

### Ejemplo 2: Comando de Orden de Trabajo

```typescript
import { VoiceCommandMode } from '@/app/components/features/voice';

function CreateWorkOrder() {
  const handleVoiceCommand = async (transcript: string) => {
    const result = await executeVoiceCommand(transcript);

    if (result.success && result.command.action === 'create_work_order') {
      // Rellenar form autom√°ticamente
      setFormData({
        priority: result.command.parameters.priority,
        assetType: result.command.parameters.assetType,
        // ...
      });
    }
  };

  return <VoiceCommandMode onCommand={handleVoiceCommand} />;
}
```

**Resultado:** "Crear orden urgente para UMA" ‚Üí Form se rellena autom√°ticamente

### Ejemplo 3: Hook Personalizado

```typescript
import { useVoiceInput } from '@/app/hooks/use-voice-input';

function CustomVoiceFeature() {
  const { startRecording, stopRecording, isRecording, transcript } = useVoiceInput({
    onTranscript: (text) => {
      console.log('Usuario dijo:', text);
      // Tu l√≥gica aqu√≠
    }
  });

  return (
    <Button
      onClick={isRecording ? stopRecording : startRecording}
      variant={isRecording ? 'destructive' : 'default'}
    >
      {isRecording ? 'Detener' : 'Hablar'}
    </Button>
  );
}
```

---

## Testing

### Tests Unitarios

**Ubicaci√≥n:** `app/actions/__tests__/actions-voice.test.ts`

**Cobertura:**

- Transcripci√≥n exitosa
- Manejo de errores
- Validaci√≥n de tama√±o
- Limpieza de timestamps

### Tests de Hooks

**Ubicaci√≥n:** `app/hooks/__tests__/use-voice-input.test.ts`

**Cobertura:**

- Estado de grabaci√≥n
- Conversi√≥n de audio
- Callbacks

### Ejecutar Tests

```bash
npm test                   # Todos los tests
npm test voice            # Solo tests de voice
npm run test:coverage     # Con cobertura
```

---

## Limitaciones y Consideraciones

### Tama√±o de Audio

- **M√°ximo:** Definido en `MAX_AUDIO_SIZE_MB`
- **Raz√≥n:** L√≠mites de API de Gemini
- **Soluci√≥n:** Validaci√≥n antes de enviar

### Idioma

- **Actual:** Solo espa√±ol (`es-ES`)
- **Futuro:** Multi-idioma configurando `language` en parser

### Precisi√≥n

- **Depende de:**
  - Calidad del micr√≥fono
  - Ruido ambiental
  - Claridad del hablante
- **Mejoras:**
  - Prompts mejorados
  - Validaci√≥n de confianza m√≠nima

### Privacidad

- **Audio NO se almacena** permanentemente
- **Se env√≠a a Gemini** para transcripci√≥n
- **Cumple:** Pol√≠ticas de Google AI

---

## Pr√≥ximos Pasos

### Mejoras T√©cnicas

- [ ] Cach√© de transcripciones frecuentes
- [ ] Compresi√≥n de audio antes de enviar
- [ ] Retry autom√°tico en errores de red
- [ ] M√©tricas de precisi√≥n

---

## Recursos Adicionales

### Documentaci√≥n Relacionada

- [API.md](../API.md) - Documentaci√≥n completa de server actions
- [AI_TOOLS_GUIDE.md](../AI_TOOLS_GUIDE.md) - Gu√≠a de herramientas de IA
- [CONTRIBUTING.md](../CONTRIBUTING.md) - Gu√≠a para contribuir

### Enlaces Externos

- [Gemini API Docs](https://ai.google.dev/docs)
- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [MediaRecorder API](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)

---

**√öltima actualizaci√≥n:** 2026-01-17  
**Versi√≥n:** 0.0.1  
**Mantenedores:** Jose Miserol, Omar Castellano
