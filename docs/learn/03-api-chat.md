# 03 â€” API del Chat (`api/chat/route.ts`)

> Es un Controlador de Interfaz de ProgramaciÃ³n de Aplicaciones (API Route o Endpoint) alojado y ejecutado exclusivamente en el lado del servidor de Next.js, funcionando como el "cerebro backend" que centraliza todo el trÃ¡fico de mensajes conversacionales. Sirve para orquestar un conducto completo de extremo a extremo: intercepta la solicitud del usuario (cuando presiona "Enviar"), ejecuta estrictos filtros de ciberseguridad (lÃ­mite de peticiones por IP, limpieza de cÃ³digo malicioso, validaciones JSON), transmite el mensaje purificado de forma segura al proveedor de IA y, finalmente, implementa una conexiÃ³n de transmisiÃ³n continua (streaming SSE) para despachar sin retraso la respuesta del asistente de regreso al navegador web. Existe principalmente por una razÃ³n crÃ­tica de arquitectura y ciberseguridad: las credenciales privadas (API Keys) de GROQ y Google Gemini cuestan dinero y son altamente confidenciales. Si nos conectÃ¡ramos a la IA directamente desde los componentes React en el navegador, cualquier persona inspeccionando la pÃ¡gina podrÃ­a robarlas; por tanto, este archivo conforma un muro protector ("servidor intermediario seguro") donde esos secretos nunca son accesibles para el cliente.

---

## ðŸ“ UbicaciÃ³n y Ruta

- **Archivo**: `app/api/chat/route.ts`
- **URL que genera**: `POST /api/chat`
- **Carpeta de tests**: `app/api/chat/__tests__/`

ðŸ§  **Concepto â€” API Routes en Next.js**: En Next.js App Router, cualquier archivo llamado `route.ts` dentro de `app/api/` se convierte automÃ¡ticamente en un endpoint HTTP. El nombre de la carpeta define la URL: `app/api/chat/route.ts` â†’ `POST /api/chat`. No necesitas Express, Fastify, ni ningÃºn otro framework â€” Next.js lo maneja por ti.

---

## ðŸ”„ Flujo Completo del Endpoint â€” Paso a Paso

Este diagrama muestra quÃ© pasa desde que el usuario presiona "Enviar" hasta que ve la respuesta:

```
Cliente (navegador)                    Servidor (Next.js)
       â”‚                                     â”‚
  1.   â”‚â”€â”€ POST /api/chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
       â”‚   Body: { messages, model }         â”‚
       â”‚                                     â”‚
       â”‚                              2. Â¿IP vÃ¡lida? â”€â”€â†’ Si no: 403 Forbidden
       â”‚                                     â”‚
       â”‚                              3. Â¿JSON vÃ¡lido? â”€â†’ Si no: 400 Bad Request
       â”‚                                     â”‚
       â”‚                              4. ChatService.processMessage()
       â”‚                                  â”œâ”€â”€ 4a. Rate limit â”€â”€â†’ Si excede: 429
       â”‚                                  â”œâ”€â”€ 4b. Validar con Zod â”€â”€â†’ Si falla: 400
       â”‚                                  â”œâ”€â”€ 4c. Sanitizar prompt
       â”‚                                  â””â”€â”€ 4d. streamText() â†’ GROQ API
       â”‚                                     â”‚
  5.   â”‚<â”€â”€ Stream de texto (SSE) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
       â”‚  Palabra por palabra:               â”‚
       â”‚  "El" "equipo" "UMA" "presenta"...  â”‚
       â”‚                                     â”‚
  6.   â”‚  âœ… Respuesta completa mostrada     â”‚
```

---

## ðŸ“„ LÃ­neas Clave â€” ExplicaciÃ³n Detallada

### Imports â€” Las Herramientas que Usa

```typescript
import { NextResponse } from 'next/server';
```

**Â¿QuÃ© es?** `NextResponse` es la clase de Next.js para crear respuestas HTTP con headers, status codes, y body estructurado. Es como `res.json()` de Express pero mÃ¡s moderno y tipado.

**Â¿Para quÃ© lo usa?** Para devolver respuestas de error (400, 429, 500) en formato JSON con headers apropiados.

```typescript
import { ChatService, RateLimitError, ValidationError } from '@/app/lib/services/chat-service';
```

**Â¿QuÃ© es?** `ChatService` es la clase que contiene toda la lÃ³gica de procesamiento del chat. `RateLimitError` y `ValidationError` son clases de error personalizadas que el servicio lanza cuando algo sale mal.

**Â¿Por quÃ© errores separados?** Porque cada tipo de error necesita una respuesta HTTP diferente. Un rate limit devuelve 429 con header `Retry-After`, mientras que un error de validaciÃ³n devuelve 400 con los detalles del problema.

```typescript
import { extractClientIP, createInvalidIPResponse } from '@/app/lib/ip-utils';
```

**Â¿QuÃ© es?** Funciones utilitarias para extraer la direcciÃ³n IP real del usuario desde los headers HTTP del request.

**Â¿Por quÃ© necesitamos la IP?** Para el rate limiter. Cada IP tiene un lÃ­mite de 20 mensajes por minuto. Sin la IP real, no podemos distinguir entre usuarios y un solo usuario podrÃ­a agotar la cuota de la API.

**Â¿Por quÃ© es complicado extraer la IP?** Porque cuando la app estÃ¡ detrÃ¡s de un proxy o CDN (como Vercel, Cloudflare, o Nginx), la IP del usuario llega en headers como `X-Forwarded-For` o `X-Real-IP`, no en la conexiÃ³n directa.

### La Constante `maxDuration`

```typescript
export const maxDuration = 30; // seconds
```

**Â¿QuÃ© es?** Le dice a Vercel (o cualquier proveedor serverless) cuÃ¡nto tiempo mÃ¡ximo puede ejecutarse esta funciÃ³n antes de ser terminada forzosamente.

**Â¿Por quÃ© 30 segundos?** Porque los modelos de IA pueden tardar varios segundos en generar respuestas largas. El default de Vercel es 10 segundos, que puede ser insuficiente para respuestas complejas.

**Â¿Para quÃ© sirve?** Si la IA se cuelga o tarda demasiado, este timeout la corta automÃ¡ticamente en vez de dejarlo colgado indefinidamente (lo que costarÃ­a dinero y bloquearÃ­a al usuario).

---

### Paso 1 â€” Validar la IP del Cliente

```typescript
const clientIP = extractClientIP(req, {
  allowLocalhost: env.NODE_ENV === 'development',
});

if (!clientIP) {
  return createInvalidIPResponse();
}
```

**Â¿QuÃ© hace?** Extrae la IP real del usuario desde los headers HTTP. En desarrollo, permite `localhost` (127.0.0.1). En producciÃ³n, exige una IP real.

**Â¿Para quÃ©?** La IP se usa despuÃ©s para el rate limiting. Si no podemos identificar al usuario, rechazamos la peticiÃ³n por seguridad.

**Â¿Por quÃ© `allowLocalhost` solo en desarrollo?** Cuando programas localmente, tu IP es `127.0.0.1` o `::1`. En producciÃ³n, estas IPs son sospechosas (podrÃ­an indicar un intento de bypass del rate limiter).

---

### Paso 2 â€” Parsear el Body JSON

```typescript
let rawBody: unknown;
try {
  rawBody = await req.json();
} catch {
  return NextResponse.json({ error: 'Invalid JSON in request body' }, { status: 400 });
}
```

**Â¿QuÃ© hace?** Intenta leer el cuerpo del request como JSON. Si falla (por ejemplo, el body estÃ¡ vacÃ­o o mal formado), devuelve un error 400 inmediatamente.

**Â¿Por quÃ© el tipo `unknown`?** En TypeScript, `unknown` es mÃ¡s seguro que `any`. Fuerza al programador a validar los datos antes de usarlos. No asumimos nada sobre la estructura del body hasta validarlo con Zod en el paso siguiente.

**Â¿Por quÃ© un try/catch separado?** Para dar un mensaje de error especÃ­fico ("JSON invÃ¡lido") en vez del error genÃ©rico del paso 5. El usuario sabe exactamente quÃ© arreglar.

---

### Paso 3 â€” Procesar con ChatService

```typescript
const chatService = new ChatService();
const result = await chatService.processMessage(rawBody, clientIP);

return result.toUIMessageStreamResponse({
  sendSources: STREAM_CONFIG.sendSources,
  sendReasoning: STREAM_CONFIG.sendReasoning,
});
```

**Â¿QuÃ© hace?** Crea una instancia del `ChatService` y le pasa el body y la IP del cliente. El servicio internamente:

1. Verifica el rate limit (Â¿esta IP ha enviado mÃ¡s de 20 mensajes en 1 minuto?)
2. Valida los datos con Zod (Â¿el body tiene la estructura correcta?)
3. Sanitiza el prompt (Â¿hay intentos de inyecciÃ³n de prompts?)
4. Llama a GROQ con `streamText()` para generar la respuesta

**Â¿QuÃ© es `toUIMessageStreamResponse()`?** Convierte el stream de la IA en un formato compatible con el hook `useChat` del frontend. El texto se envÃ­a en tiempo real usando Server-Sent Events (SSE), no todo de golpe.

ðŸ§  **Concepto â€” Streaming vs Response completa**: Imagina pedir una pizza. **Sin streaming**: esperas 30 minutos y te traen toda la pizza de golpe. **Con streaming**: te van sirviendo cada porciÃ³n conforme sale del horno. El usuario ve las palabras aparecer una por una, igual que en ChatGPT.

**Â¿QuÃ© es `STREAM_CONFIG`?** Un objeto de configuraciÃ³n (definido en `config/server.ts`) que controla si se envÃ­an las fuentes citadas y el razonamiento interno de la IA. Actualmente ambos estÃ¡n desactivados.

---

### Paso 4 â€” Manejo de Errores EspecÃ­ficos

```typescript
if (error instanceof RateLimitError) {
  return createRateLimitResponse(error.retryAfter);
}
```

**Â¿QuÃ© hace?** Si el `ChatService` lanza un `RateLimitError`, devolvemos un HTTP 429 (Too Many Requests) con el header `Retry-After` indicando cuÃ¡ntos segundos debe esperar el usuario.

**Â¿Por quÃ© un tipo de error especÃ­fico?** Porque HTTP define cÃ³digos de estado semÃ¡nticos. Cada error tiene su cÃ³digo:

- **429** = "EstÃ¡s haciendo peticiones demasiado rÃ¡pido, espera un momento"
- **400** = "Los datos que enviaste no son vÃ¡lidos"
- **500** = "Algo se rompiÃ³ en el servidor, no es tu culpa"

```typescript
if (error instanceof ValidationError) {
  return createValidationErrorResponse(error.details);
}
```

**Â¿QuÃ© hace?** Si Zod rechaza el body (campos faltantes, tipos incorrectos, etc.), devolvemos 400 con los detalles especÃ­ficos de quÃ© validaciÃ³n fallÃ³. AsÃ­ el frontend puede mostrar un mensaje descriptivo.

### Paso 5 â€” Error GenÃ©rico (Fallback)

```typescript
logger.error('Error en API de chat', error, {
  component: 'ChatAPIRoute',
  action: 'POST',
});

return NextResponse.json(
  { error: ERROR_MESSAGES.PROCESSING_ERROR, details: errorMessage },
  { status: 500 }
);
```

**Â¿QuÃ© hace?** Para cualquier error no previsto (un bug, una API caÃ­da, un timeout inesperado), loggeamos el error completo (con stack trace) y devolvemos un 500 genÃ©rico al cliente.

**Â¿Por quÃ© loggear antes de responder?** Porque el mensaje al usuario es genÃ©rico ("Error de procesamiento"). El log detallado es para el desarrollador que investiga el problema despuÃ©s. Sin el log, el error se perderÃ­a.

---

### Helper: `createRateLimitResponse()`

```typescript
function createRateLimitResponse(retryAfterSeconds: number): NextResponse {
  return NextResponse.json(
    {
      error: ERROR_MESSAGES.RATE_LIMIT,
      message: ERROR_MESSAGES.QUOTA_EXCEEDED_DESCRIPTION,
      retryAfter: retryAfterSeconds,
    },
    {
      status: 429,
      headers: {
        'Retry-After': retryAfterSeconds.toString(),
        'X-RateLimit-Remaining': '0',
      },
    }
  );
}
```

**Â¿QuÃ© es el header `Retry-After`?** Es un header estÃ¡ndar de HTTP (RFC 7231) que le dice al cliente cuÃ¡ntos segundos debe esperar antes de reintentar. Navegadores y clientes HTTP respetuosos leen este header automÃ¡ticamente.

**Â¿QuÃ© es `X-RateLimit-Remaining`?** Es un header no estÃ¡ndar (por eso la "X") pero convencional en APIs REST. Indica cuÃ¡ntas peticiones le quedan al cliente. En este caso, 0.

---

## ðŸ§  Conceptos Clave

### Â¿QuÃ© es un API Route en Next.js?

En frameworks tradicionales (Express, Flask), creas un archivo de rutas y las registras manualmente. En Next.js App Router, es automÃ¡tico:

```
Carpeta                    â†’  URL generada
app/api/chat/route.ts      â†’  POST /api/chat
app/api/users/route.ts     â†’  GET/POST /api/users
app/api/orders/[id]/route.ts â†’ GET /api/orders/123
```

Solo necesitas exportar funciones con el nombre del mÃ©todo HTTP (`GET`, `POST`, `PUT`, `DELETE`).

### Â¿QuÃ© es SSE (Server-Sent Events)?

Es un protocolo web que permite al servidor enviar datos al cliente continuamente a travÃ©s de una sola conexiÃ³n HTTP. A diferencia de WebSockets (que son bidireccionales), SSE es unidireccional: solo del servidor al cliente. Es perfecto para streaming de texto de IA porque el cliente solo necesita recibir, no enviar.

---

## ðŸ”— Archivos Relacionados

| Archivo                        | Â¿QuÃ© relaciÃ³n tiene?                                                    | Â¿Por quÃ© es importante?                                                                          |
| ------------------------------ | ----------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------ |
| `lib/services/chat-service.ts` | Es el servicio que este endpoint instancia y usa para procesar mensajes | Contiene toda la lÃ³gica de negocio: rate limiting, validaciÃ³n, sanitizaciÃ³n, y la llamada a GROQ |
| `lib/rate-limiter.ts`          | Implementa el algoritmo de rate limiting que `ChatService` usa          | Define que mÃ¡ximo 20 mensajes por minuto por IP estÃ¡n permitidos                                 |
| `lib/ip-utils.ts`              | Proporciona las funciones de extracciÃ³n de IP que se usan en el paso 1  | Sin estas funciones, no podrÃ­amos identificar al usuario para el rate limiting                   |
| `lib/schemas/chat.ts`          | Define el schema Zod que valida el body del request en el paso 4b       | Garantiza que `messages` sea un array vÃ¡lido y `model` sea un modelo permitido                   |
| `config/server.ts`             | Contiene `STREAM_CONFIG` y el `SYSTEM_PROMPT` que se inyecta a la IA    | Define la personalidad del asistente y los parÃ¡metros de streaming                               |
| `constants/messages.ts`        | Proporciona los mensajes de error estÃ¡ndar (`ERROR_MESSAGES`)           | Garantiza que los mismos errores siempre muestren el mismo mensaje al usuario                    |

---

**â† Anterior**: [02 â€” Punto de Entrada](./02-punto-de-entrada.md) | **Siguiente**: [04 â€” Server Actions](./04-server-actions.md) â†’
